# HandGaze ğŸ‘‹ 

<div align="center">

![HandGaze Logo](https://img.shields.io/badge/HandGaze-Vision-blue?style=for-the-badge&logo=opencv)

[![Python](https://img.shields.io/badge/python-v3.7+-blue.svg?style=for-the-badge&logo=python)](https://www.python.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-Latest-green.svg?style=for-the-badge&logo=google)](https://mediapipe.dev/)
[![OpenCV](https://img.shields.io/badge/OpenCV-Latest-red.svg?style=for-the-badge&logo=opencv)](https://opencv.org/)
[![License](https://img.shields.io/badge/license-GNU_GPL_v3-blue.svg?style=for-the-badge&logo=gnu)](LICENSE)

> *Transform your hand gestures into digital communication with AI-powered recognition* âœ¨

[Features](docs/FEATURES.md) â€¢ [Installation](#-quick-start) â€¢ [Usage](#-basic-usage) â€¢ [Documentation](docs/README.md)

---

<p align="center">
  <img src="docs/demo.gif" alt="HandGaze Demo" width="600"/>
</p>

</div>

## ğŸ“š Quick Documentation

<div align="center">

<table>
<tr>
<td align="center" width="25%">

### ğŸ“–
[Full Documentation](docs/README.md)

Complete guide

</td>
<td align="center" width="25%">

### âœ¨
[Features Guide](docs/FEATURES.md)

All features

</td>
<td align="center" width="25%">

### ğŸ¯
[API Reference](docs/README.md#-api-reference)

Technical details

</td>
<td align="center" width="25%">

### ğŸ”§
[Troubleshooting](docs/README.md#-troubleshooting)

Common issues

</td>
</tr>
</table>

</div>

## ğŸŒŸ What is HandGaze?

HandGaze is a cutting-edge computer vision application that revolutionizes digital communication through AI-powered hand gesture recognition. Create sentences, type words, and interact with your computer using natural hand movements - all in real-time!

<div align="center">

```mermaid
graph LR
    A[ğŸ‘ï¸ Camera Input] --> B[ğŸ¤š Hand Detection]
    B --> C[ğŸ“ Landmark Tracking]
    C --> D[ğŸ¯ Gesture Recognition]
    D --> E[ğŸ’­ Word Processing]
    E --> F[ğŸ“ Sentence Creation]
    style A fill:#ff9999,stroke:#ff0000,stroke-width:2px,color:#990000,font-weight:bold
    style B fill:#99ff99,stroke:#00ff00,stroke-width:2px,color:#006600,font-weight:bold
    style C fill:#9999ff,stroke:#0000ff,stroke-width:2px,color:#000099,font-weight:bold
    style D fill:#ffff99,stroke:#ffff00,stroke-width:2px,color:#999900,font-weight:bold
    style E fill:#ff99ff,stroke:#ff00ff,stroke-width:2px,color:#990099,font-weight:bold
    style F fill:#99ffff,stroke:#00ffff,stroke-width:2px,color:#009999,font-weight:bold
    linkStyle default stroke:#333333,stroke-width:2px
```

</div>

## âœ¨ Features

- ğŸ¯ **Real-time Hand Recognition**
  - Advanced hand tracking using MediaPipe
  - Robust landmark detection
  - Real-time gesture feedback

- ğŸ”¤ **Gesture Training System**
  - Interactive gesture training interface
  - Visual feedback during training
  - Gesture testing with confidence scoring
  - Automatic data backup and validation

- ğŸ“š **Smart Dictionary Integration**
  - Offline dictionary with spell checking
  - Word suggestions and auto-correction
  - Enhanced word frequency analysis
  - Efficient data storage and retrieval

- ğŸ¨ **User Experience**
  - Intuitive visual feedback
  - Progress tracking
  - Real-time confidence scoring
  - Error handling and recovery

## ğŸ¯ Latest Updates (v2.1)

<table>
<tr>
<td width="50%">

### âœ¨ New Features

- **Enhanced Gesture Recognition**
  - Improved accuracy (95%+)
  - Faster response time (0.8s)
  - Multi-hand support
  
- **Advanced Text Processing**
  - Predictive text suggestions
  - Auto-capitalization
  - Punctuation gestures

</td>
<td width="50%">

### ğŸ› ï¸ Technical Updates

- **Core Improvements**
  - Optimized MediaPipe integration
  - Reduced CPU usage by 30%
  - Better error recovery

- **User Experience**
  - Dynamic confidence indicators
  - Gesture training improvements
  - Real-time performance metrics

</td>
</tr>
</table>

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

```bash
Python 3.7+
OpenCV-compatible webcam
4GB RAM minimum
Internet (for initial setup)
```

### âš¡ One-Line Installation

```bash
git clone https://github.com/notcaliper/HandGaze.git && cd HandGaze && pip install -r requirements.txt
```

### ğŸ® Basic Usage

1. **Launch HandGaze**
   ```bash
   python hand_recognition.py
   ```

2. **Train Custom Gestures (Optional)**
   ```bash
   python gesture_trainer.py
   ```

3. **Gesture Controls**
   - ğŸ”¤ Use ASL gestures for letters
   - ğŸ‘‹ Hold "SPACE" gesture (0.8s) for spaces
   - âœŒï¸ Hold "BACKSPACE" gesture (0.8s) to delete
   - âœŠ "SHIFT" gesture for capitalization
   - ğŸ‘† "PERIOD" gesture for punctuation

## ğŸ’¡ Pro Tips

<table>
<tr>
<td width="50%">

### ğŸ¯ For Best Recognition

- Maintain good lighting
- Keep hands within frame
- Make deliberate gestures
- Position camera at eye level
- Use the training mode for custom gestures

</td>
<td width="50%">

### âš¡ For Better Performance

- Close background applications
- Enable hardware acceleration
- Update gesture database regularly
- Use suggested word completions
- Keep hands 2-3 feet from camera

</td>
</tr>
</table>

## ğŸ› ï¸ Project Structure

```
HandGaze/
â”œâ”€â”€ ğŸ“œ hand_recognition.py  # Main recognition system
â”œâ”€â”€ ğŸ¯ object_detector.py   # Object detection
â”œâ”€â”€ ğŸ“š offline_dictionary.py # Word suggestions
â”œâ”€â”€ âš™ï¸ gesture_trainer.py   # Custom gesture training
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Dependencies
â”œâ”€â”€ ğŸ“– docs/               # Documentation
â”‚   â”œâ”€â”€ README.md          # Full guide
â”‚   â””â”€â”€ FEATURES.md        # Features guide
â””â”€â”€ ğŸ“ data/
    â”œâ”€â”€ dictionary_data/    # Word database
    â””â”€â”€ gesture_data/       # Trained gestures
```

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

- ğŸ› Report bugs and issues
- ğŸ’¡ Suggest new features
- ğŸ”§ Submit pull requests
- ğŸ“š Improve documentation

## ğŸ“„ License

HandGaze is GNU GPLv3 licensed. See [LICENSE](LICENSE) for details.

---

<div align="center">

Made with â¤ï¸ by [NotCaliper](https://github.com/notcaliper)

</div>
